# Perguntas Frequentes T√©cnicas
## Complemento √† Proposta de Arquitetura de Dados

Este documento antecipa perguntas t√©cnicas que um especialista em Analytics Engineering provavelmente far√° durante a apresenta√ß√£o.

---

## 1. Decis√µes de Arquitetura e Trade-offs

### Por que GCP e n√£o AWS/Azure?

**GCP (escolhido)**:
‚úÖ BigQuery √© o melhor Data Warehouse serverless do mercado (performance/custo)
‚úÖ Integra√ß√£o nativa entre servi√ßos (Dataform, Datastream, Composer)
‚úÖ Dataform inclu√≠do no BigQuery (custo zero vs dbt Cloud)
‚úÖ BigQuery ML permite modelos em SQL (acess√≠vel para analistas)

**AWS (n√£o escolhido)**:
‚ùå Redshift √© mais caro e menos perform√°tico que BigQuery
‚ùå Glue ETL tem curva de aprendizado maior
‚ùå S3 + Athena √© bom, mas n√£o compete com BigQuery em queries complexas
‚úÖ Maior ecossistema e ado√ß√£o no mercado

**Azure (n√£o escolhido)**:
‚ùå Synapse ainda est√° amadurecendo
‚ùå Integra√ß√£o entre servi√ßos menos fluida que GCP
‚úÖ Boa escolha se empresa j√° usa Azure AD/Office 365

**Decis√£o**: GCP oferece o melhor custo-benef√≠cio para uma arquitetura moderna de dados, especialmente com BigQuery + Dataform. **Risco de vendor lock-in √© mitigado** por usar padr√µes abertos (SQL, Parquet, Airflow).

---

### Por que Dataform e n√£o dbt Core?

**Dataform (escolhido)**:
‚úÖ Gerenciado pelo Google (zero ops, sem servidor para manter)
‚úÖ Git integrado nativamente
‚úÖ Custo zero (inclu√≠do no BigQuery)
‚úÖ Otimizado para BigQuery (query compilation)
‚úÖ Sintaxe similar ao dbt (migra√ß√£o futura √© vi√°vel)

**dbt Core (n√£o escolhido)**:
‚ùå Requer infraestrutura (Docker, Cloud Run, ou VM)
‚ùå Manuten√ß√£o de depend√™ncias Python
‚ùå dbt Cloud √© pago ($100+/m√™s por developer)
‚úÖ Maior ecossistema (packages, community)
‚úÖ Melhor documenta√ß√£o

**Trade-off aceito**: Menor ecossistema do Dataform vs. facilidade operacional. Se futuramente precisarmos migrar para dbt, a estrutura de projeto √© compat√≠vel (staging ‚Üí intermediate ‚Üí marts).

**Estrat√©gia de sa√≠da**: Manter compatibilidade conceitual com dbt. Usar CTEs ao inv√©s de macros complexas. Documentar depend√™ncias explicitamente.

---

### Por que Cloud Composer ($200/m√™s) e n√£o Cloud Workflows ($20/m√™s)?

**Cloud Composer (Airflow)**:
‚úÖ Padr√£o da ind√∫stria (portabilidade)
‚úÖ Python completo (flexibilidade total)
‚úÖ Retry logic, backfilling, SLA tracking robusto
‚úÖ UI rica para debugging
‚úÖ Operadores nativos para GCP (Dataform, BigQuery)

**Cloud Workflows (n√£o escolhido)**:
‚ùå YAML-based (menos expressivo que Python)
‚ùå Debugging mais dif√≠cil
‚ùå Menos ferramentas de observabilidade
‚úÖ 10x mais barato ($20 vs $200)

**Decis√£o**: Airflow vale o investimento pela robustez e observabilidade. Em um ambiente de produ√ß√£o, economia de $180/m√™s n√£o justifica perder visibilidade e controle sobre pipelines cr√≠ticos.

---

## 2. Aspectos Pr√°ticos de Implementa√ß√£o

### Como lidar com Schema Evolution?

**Cen√°rio**: Tabela `customers` no PostgreSQL adiciona nova coluna `customer_tier`.

**Estrat√©gia**:

1. **Bronze Layer**: Schema evolution autom√°tico
   - Datastream e Fivetran detectam novas colunas automaticamente
   - BigLake external tables leem schema do Parquet (compat√≠vel)

2. **Silver Layer**: Atualiza√ß√£o manual controlada
   ```sql
   -- definitions/staging/core/stg_postgres__customers.sqlx

   -- Adicionar nova coluna com NULL safety
   COALESCE(customer_tier, 'standard') AS customer_tier,
   ```
   - Pull request obrigat√≥rio (code review)
   - Deploy em staging primeiro
   - Testes validam que coluna n√£o quebrou queries existentes

3. **Gold Layer**: Impact analysis antes de propagar
   - Verificar quais marts usam `customers`
   - Decidir se `customer_tier` deve ser dimens√£o ou m√©trica
   - Comunicar mudan√ßa para consumidores (Slack #data-changes)

**Breaking Changes** (ex: coluna removida):
- Manter coluna antiga como `DEPRECATED_` por 30 dias
- Alertar consumidores via Slack e email
- Criar issue no Jira para rastrear migra√ß√£o
- Ap√≥s 30 dias, remover com feature flag

---

### Como fazer Backfilling de dados hist√≥ricos?

**Cen√°rio**: Novo modelo `fct_customer_health` precisa de dados dos √∫ltimos 12 meses.

**Estrat√©gia**:

1. **Validar disponibilidade de dados Bronze**
   ```sql
   SELECT
     MIN(DATE(_PARTITIONTIME)) AS oldest_date,
     MAX(DATE(_PARTITIONTIME)) AS newest_date,
     COUNT(DISTINCT DATE(_PARTITIONTIME)) AS days_available
   FROM `bronze_postgres.customers`;
   ```

2. **Criar DAG de backfill separado** (n√£o o DAG di√°rio)
   ```python
   # dags/backfill_customer_health.py

   from airflow import DAG
   from datetime import datetime, timedelta

   with DAG(
       'backfill_customer_health',
       start_date=datetime(2024, 1, 1),  # 12 meses atr√°s
       end_date=datetime(2025, 1, 1),
       schedule_interval='@daily',
       catchup=True,  # IMPORTANTE: True para backfill
       max_active_runs=5,  # Paralelizar 5 dias por vez
   ) as dag:

       run_customer_health = DataformCreateWorkflowInvocationOperator(
           task_id='backfill_customer_health',
           workflow_invocation={
               'invocation_config': {
                   'included_tables': ['fct_customer_health'],
                   'vars': {
                       'execution_date': '{{ ds }}'  # Cada dia
                   }
               }
           }
       )
   ```

3. **Monitorar custos**
   - Backfill de 12 meses pode custar ~$50-100 (scan de dados hist√≥ricos)
   - Executar em hor√°rio de menor tr√°fego (madrugada)

4. **Validar consist√™ncia**
   - Comparar contagens por dia com expectativa
   - Rodar testes de qualidade em amostra (1%, 5%, 10%)

---

### Como fazer Rollback de modelo com erro?

**Cen√°rio**: Deploy de `fct_monthly_recurring_revenue` v2 tem bug (MRR negativo).

**Estrat√©gia de Rollback**:

1. **Identifica√ß√£o r√°pida** (< 5 min)
   - Alerta autom√°tico: "MRR negativo detectado"
   - Slack #data-alerts notifica on-call

2. **Rollback Git** (< 10 min)
   ```bash
   git revert abc123  # Commit com erro
   git push origin main
   ```
   - CI/CD deploya automaticamente vers√£o anterior
   - Cloud Composer re-executa DAG com c√≥digo correto

3. **Se dados j√° foram consumidos** (Looker, notebooks):
   ```sql
   -- Deletar dados errados
   DELETE FROM `gold_revenue_ops.fct_monthly_recurring_revenue`
   WHERE _updated_at >= '2025-10-14 10:00:00';

   -- Re-executar pipeline correto
   -- (via Airflow UI ou gcloud)
   ```

4. **Post-mortem** (24h depois)
   - Documentar causa raiz
   - Adicionar teste para prevenir regress√£o
   - Atualizar runbook de rollback

**Preven√ß√£o**:
- Sempre testar em staging antes de produ√ß√£o
- Usar feature flags para rollout gradual
- Manter vers√µes antigas de tabelas por 7 dias (snapshots)

---

### Como onboardar nova fonte de dados?

**Processo padronizado** (exemplo: adicionar Zendesk para tickets de suporte):

**Semana 1: Discovery**
1. Reuni√£o com stakeholder (Customer Success)
   - Entender use cases (dashboard de CSAT, time to resolution)
   - Definir SLA (D+1 √© suficiente?)
   - Identificar campos cr√≠ticos (ticket_id, customer_id, status, satisfaction_score)

2. An√°lise t√©cnica
   - Verificar API do Zendesk (rate limits, autentica√ß√£o)
   - Estimar volume (100k tickets/m√™s?)
   - Calcular custo (Fivetran: ~$120/m√™s)

**Semana 2: Implementa√ß√£o Bronze**
3. Setup de conector
   - Configurar Fivetran: Zendesk ‚Üí Cloud Storage (Bronze)
   - Validar ingest√£o: 1 semana de dados hist√≥ricos

4. Criar external table
   ```sql
   CREATE EXTERNAL TABLE `bronze_zendesk.tickets` ...
   ```

**Semana 3: Transforma√ß√£o Silver**
5. Modelo staging
   ```sql
   -- definitions/staging/support/stg_zendesk__tickets.sqlx
   ```
   - Deduplica√ß√£o, type casting, normaliza√ß√£o

6. Testes de qualidade
   - Dataform assertions (uniqueKey, nonNull)
   - Dataplex DQ rules (completeness > 99%)

**Semana 4: Consumo Gold**
7. Mart de neg√≥cio
   ```sql
   -- definitions/marts/support/fct_support_tickets.sqlx
   ```
   - Join com `customers`, `products`
   - Calcular m√©tricas (avg resolution time, CSAT by segment)

8. Dashboard Looker
   - "Customer Support Overview"
   - KPIs: CSAT, backlog, time to resolution

**Checklist de conclus√£o**:
- [ ] Dados em Bronze (validado)
- [ ] Modelo Silver com testes
- [ ] Modelo Gold documentado
- [ ] Dashboard em produ√ß√£o
- [ ] Treinamento para analistas
- [ ] Documenta√ß√£o no Data Catalog

---

## 3. Governan√ßa e Compliance

### Como garantir LGPD/GDPR compliance?

**Right to be Forgotten** (Art. 17 GDPR, Art. 18 LGPD):

**Processo**:
1. Cliente solicita exclus√£o de dados pessoais
2. Sistema CRM registra solicita√ß√£o
3. Trigger autom√°tico no Airflow:
   ```python
   # dags/gdpr_right_to_be_forgotten.py

   def anonymize_customer_data(customer_id):
       # Anonimizar em todas as camadas
       queries = [
           # Silver
           f"""
           UPDATE `silver_core.customers`
           SET
             email = 'anonymized_{customer_id}@deleted.com',
             company_name = 'ANONYMIZED',
             phone_clean = NULL,
             document_number = NULL,
             _anonymized_at = CURRENT_TIMESTAMP()
           WHERE customer_id = '{customer_id}'
           """,
           # Gold (propaga√ß√£o)
           f"""
           UPDATE `gold_revenue_ops.fct_customer_health`
           SET customer_id = 'ANONYMIZED_{customer_id}'
           WHERE customer_id = '{customer_id}'
           """
       ]

       for q in queries:
           client.query(q).result()
   ```

4. **Bronze Layer**: Dados raw permanecem (auditoria legal), mas com flag
   ```sql
   UPDATE bronze.customers
   SET _gdpr_deleted = TRUE
   WHERE customer_id = '{customer_id}'
   ```

5. Confirma√ß√£o para cliente (email autom√°tico)

**Data Minimization** (coletar apenas o necess√°rio):
- Policy tags identificam PII automaticamente (Cloud DLP)
- Revis√£o trimestral: "Esta coluna ainda √© necess√°ria?"

**Access Logs**:
```sql
-- Auditoria: quem acessou dados de customer_id X?
SELECT
  principal_email,
  query,
  start_time
FROM `region-us.INFORMATION_SCHEMA.JOBS_BY_PROJECT`
WHERE query LIKE '%customer_id = \'12345\'%'
  AND start_time >= TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 90 DAY)
ORDER BY start_time DESC;
```

---

### Como funciona Disaster Recovery?

**Cen√°rio 1: Tabela Gold deletada acidentalmente**

**Recovery**:
```sql
-- BigQuery Time Travel (at√© 7 dias)
CREATE TABLE `gold_revenue_ops.fct_monthly_recurring_revenue` AS
SELECT * FROM `gold_revenue_ops.fct_monthly_recurring_revenue`
  FOR SYSTEM_TIME AS OF TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 1 HOUR);
```

**Cen√°rio 2: Corrup√ß√£o de dados (bug em transforma√ß√£o)**

**Recovery**:
1. Identificar timestamp do erro
2. Restaurar de snapshot:
   ```sql
   -- Snapshots di√°rios autom√°ticos (via Cloud Composer)
   CREATE TABLE `gold_revenue_ops.fct_monthly_recurring_revenue` AS
   SELECT * FROM `gold_revenue_ops.fct_monthly_recurring_revenue_snapshot_20251013`;
   ```

3. Re-executar pipeline a partir do Bronze (dados raw imut√°veis)

**Cen√°rio 3: Regi√£o GCP inteira cai (raro, mas poss√≠vel)**

**Mitigation**:
- **Cross-region replication** (Bronze layer):
  ```bash
  gsutil rsync -r \
    gs://conta-azul-datalake/bronze/ \
    gs://conta-azul-datalake-backup-us/bronze/
  ```
  - Cron di√°rio (via Cloud Scheduler)
  - Custo: ~$50/m√™s (network egress)

- **BigQuery snapshots cross-region**:
  ```sql
  -- Snapshot semanal para regi√£o US
  EXPORT DATA OPTIONS(
    uri='gs://conta-azul-datalake-backup-us/snapshots/gold_revenue_ops/*',
    format='PARQUET'
  ) AS
  SELECT * FROM `gold_revenue_ops.fct_monthly_recurring_revenue`;
  ```

**RTO (Recovery Time Objective)**: 4 horas
**RPO (Recovery Point Objective)**: 24 horas (dados at√© ontem)

---

## 4. Crescimento e Escala

### Como os custos escalam com crescimento?

**Cen√°rio de crescimento** (pr√≥ximos 2 anos):

| M√©trica | Hoje | 6 meses | 1 ano | 2 anos |
|---------|------|---------|-------|--------|
| **Dados novos/m√™s** | 100 GB | 200 GB | 400 GB | 1 TB |
| **Eventos/dia** | 500k | 1M | 2M | 5M |
| **Queries/m√™s** | 2 TB | 4 TB | 8 TB | 20 TB |
| **Usu√°rios ativos** | 50 | 75 | 100 | 150 |

**Proje√ß√£o de custos**:

| Servi√ßo | Hoje | 6 meses | 1 ano | 2 anos |
|---------|------|---------|-------|--------|
| **Cloud Storage** | $20 | $35 | $60 | $150 |
| **BigQuery Storage** | $25 | $45 | $80 | $200 |
| **BigQuery Compute** | $10 | $20 | $40 | $100 |
| **Fivetran** | $120 | $180 | $240 | $360 |
| **Cloud Composer** | $200 | $300* | $500* | $800* |
| **Outros** | $325 | $420 | $580 | $890 |
| **TOTAL/m√™s** | **$700** | **$1,000** | **$1,500** | **$2,500** |

*Composer: Small ‚Üí Medium ‚Üí Large environment

**Breaking points** (quando ajustar infra):

- **6 meses**:
  - Aumentar Cloud Composer para Medium (2 vCPUs)
  - Adicionar BigQuery BI Engine ($100/m√™s) para cache de dashboards

- **1 ano**:
  - Avaliar BigQuery Reservations (slots dedicados) se queries > 10 TB/m√™s
  - Implementar partitioning mais granular (hourly em eventos)

- **2 anos**:
  - Considerar Cloud Composer Large ou Kubernetes (GKE) para Airflow
  - Implementar data archiving (mover Bronze > 6 meses para Coldline)

**Otimiza√ß√µes para conter crescimento de custos**:
1. Materialized views ao inv√©s de tables em Gold (recompute apenas o necess√°rio)
2. Clustering agressivo em colunas de filtro
3. Looker PDT caching (reduzir queries repetitivas)
4. Educa√ß√£o de usu√°rios (evitar `SELECT *`)

---

## 5. Data Quality em Produ√ß√£o

### O que acontece se dados falharem em testes Silver?

**Cen√°rio**: Ingest√£o de `customers` tem 50% de emails nulos (deveria ser < 1%).

**Fluxo de tratamento**:

1. **Detec√ß√£o autom√°tica** (Dataform assertion falha)
   ```
   [ERROR] silver_core.customers: Assertion failed
   - Rule: nonNull(email)
   - Expected: 100%
   - Actual: 50%
   ```

2. **Pipeline para e notifica** (fail-fast)
   - Airflow task marca como FAILED
   - Slack #data-alerts: "üö® CRITICAL: Silver layer quality check failed"
   - Email para data-eng-oncall

3. **Dados v√£o para Quarantine**
   ```sql
   -- Isolar dados problem√°ticos
   CREATE TABLE `quarantine.customers_failed_20251014` AS
   SELECT * FROM ${ref("bronze_postgres", "customers")}
   WHERE email IS NULL;

   -- Processar apenas dados bons
   INSERT INTO silver_core.customers
   SELECT * FROM cleaned
   WHERE email IS NOT NULL;
   ```

4. **Investiga√ß√£o** (SLA: 2 horas)
   - Checar fonte (PostgreSQL): Bug na aplica√ß√£o?
   - Checar Datastream: Falha na captura CDC?
   - Checar Bronze: Arquivos Parquet corrompidos?

5. **Resolu√ß√£o**:
   - **Se bug na fonte**: Abrir ticket para time de Engineering
   - **Se problema tempor√°rio**: Re-executar ingest√£o ap√≥s corre√ß√£o
   - **Se problema estrutural**: Ajustar l√≥gica Silver para tolerar (com documenta√ß√£o)

6. **Comunica√ß√£o**:
   ```
   Slack #data-updates:
   "‚ö†Ô∏è Delay em silver_core.customers (14/10 10h)
   - Causa: Bug na aplica√ß√£o (email nulls)
   - Impacto: Dashboards de RevOps desatualizados
   - ETA resolu√ß√£o: 14/10 14h
   - Ticket: JIRA-12345"
   ```

**Quarantine Retention**: 30 dias (depois deletar ou arquivar)

---

### Como notificar data producers de problemas?

**Data Contract** (SLA reverso: fonte ‚Üí warehouse):

```yaml
# contracts/postgres_customers.yaml

source: postgres_production.customers
owner: engineering@contaazul.com
sla:
  freshness: < 5 minutes  # CDC real-time
  completeness:
    email: 99.5%
    created_at: 100%
  uniqueness:
    id: 100%

alerts:
  - condition: email_null_rate > 1%
    severity: HIGH
    notify:
      - engineering@contaazul.com
      - Slack: #engineering-alerts

  - condition: cdc_lag > 15 minutes
    severity: CRITICAL
    notify:
      - sre-oncall@contaazul.com
      - PagerDuty
```

**Monitoramento autom√°tico**:
```python
# dags/data_contract_monitor.py

def check_data_contracts():
    for contract in load_contracts():
        actual_stats = get_table_stats(contract.source)

        violations = []
        if actual_stats['email_null_rate'] > 0.01:  # 1%
            violations.append({
                'rule': 'email completeness',
                'expected': '99.5%',
                'actual': f"{(1-actual_stats['email_null_rate'])*100}%"
            })

        if violations:
            send_alert(
                recipients=contract.owner,
                subject=f"Data Contract Violation: {contract.source}",
                violations=violations
            )
```

**Dashboard de Data Contracts**:
- Looker dashboard: "Data Source Health"
- M√©tricas: Uptime, freshness, quality score
- Por fonte: PostgreSQL (‚úÖ 99.8%), Salesforce (‚ö†Ô∏è 95.2%)

---

## 6. Perguntas de Arquitetura Avan√ßadas

### Como garantir idempot√™ncia nos pipelines?

**Problema**: Re-executar pipeline n√£o deve duplicar dados nem causar inconsist√™ncias.

**Solu√ß√£o por camada**:

**Bronze** (naturalmente idempotente):
- Datastream: CDC usa log sequence number (LSN) ‚Üí n√£o duplica
- Fivetran: Usa cursor de √∫ltima execu√ß√£o ‚Üí idempotente
- Cloud Storage: Particionamento por data (`year=2025/month=10/day=14/`) ‚Üí sobrescreve

**Silver** (incremental idempotente):
```sql
-- definitions/staging/core/stg_postgres__customers.sqlx

pre_operations {
  -- DELETAR registros que ser√£o re-processados
  ${when(incremental(),
    `DELETE FROM ${self()}
     WHERE customer_id IN (
       SELECT DISTINCT id
       FROM ${ref("bronze_postgres", "customers")}
       WHERE DATE(_loaded_at) = '{{ ds }}'
     )`
  )}
}

-- INSERT apenas dados do dia (idempotente)
INSERT INTO ${self()}
SELECT * FROM cleaned
WHERE DATE(_loaded_at) = '{{ ds }}';
```

**Gold** (full refresh idempotente):
```sql
-- Marts s√£o sempre full refresh (recompute tudo)
-- Idempotente por design: DROP + CREATE

CREATE OR REPLACE TABLE gold_revenue_ops.fct_monthly_recurring_revenue AS
SELECT ... FROM silver_core.customers;
```

**Teste de idempot√™ncia**:
```python
# tests/test_idempotency.py

def test_silver_customers_idempotent():
    # Executar pipeline 2x para mesma data
    run_dataform(execution_date='2025-10-14')
    count_1 = get_row_count('silver_core.customers', date='2025-10-14')

    run_dataform(execution_date='2025-10-14')  # Re-executar
    count_2 = get_row_count('silver_core.customers', date='2025-10-14')

    assert count_1 == count_2, "Pipeline n√£o √© idempotente!"
```

---

### Como lidar com late-arriving data?

**Problema**: Evento de 14/10 chega no warehouse dia 16/10.

**Estrat√©gia**:

**Silver** (partition by event_date, not ingestion_date):
```sql
-- Particionamento por data DO EVENTO (n√£o da ingest√£o)
config {
  bigquery: {
    partitionBy: "event_date"  -- ‚úÖ Correto
    -- N√ÉO: partitionBy: "_loaded_at"  -- ‚ùå Errado
  }
}

-- Late data vai para parti√ß√£o correta
INSERT INTO silver_product_analytics.events
SELECT
  event_id,
  CAST(event_timestamp AS DATE) AS event_date,  -- Partition key
  ...
WHERE DATE(event_timestamp) BETWEEN '2025-10-01' AND CURRENT_DATE();
```

**Gold** (lookback window de 3 dias):
```sql
-- Reprocessar √∫ltimos 3 dias para capturar late data
CREATE OR REPLACE TABLE gold_product_analytics.fct_daily_active_users AS
SELECT
  event_date,
  COUNT(DISTINCT user_id) AS dau
FROM silver_product_analytics.events
WHERE event_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 3 DAY)
GROUP BY 1;
```

**Monitoramento**:
```sql
-- Alertar se late data > 5% do volume
SELECT
  event_date,
  COUNT(*) AS total_events,
  COUNT(CASE WHEN DATE(_loaded_at) > DATE_ADD(event_date, INTERVAL 2 DAY) THEN 1 END) AS late_events,
  SAFE_DIVIDE(late_events, total_events) AS late_percentage
FROM silver_product_analytics.events
WHERE event_date >= DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY)
HAVING late_percentage > 0.05;
```

---

## Conclus√£o

Esta documenta√ß√£o complementar antecipa as perguntas mais comuns de um **Analytics Engineer especialista** e demonstra:

1. **Profundidade t√©cnica**: N√£o apenas "o que", mas "como" e "por qu√™"
2. **Experi√™ncia pr√°tica**: Problemas reais e solu√ß√µes testadas
3. **Pensamento cr√≠tico**: Trade-offs expl√≠citos, n√£o apenas benef√≠cios
4. **Maturidade**: Processos, n√£o apenas tecnologia

**Recomenda√ß√£o**: Use este documento como **anexo t√©cnico** durante a apresenta√ß√£o. N√£o precisa cobrir tudo, mas demonstra que voc√™ pensou nos detalhes.
